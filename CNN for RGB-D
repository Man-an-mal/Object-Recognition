{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11690806,"sourceType":"datasetVersion","datasetId":7337770}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration\ndataset_path = \"/kaggle/input/rgb-d-cropped/rgbd-dataset_eval\"\nbatch_size = 32\nnum_workers = 2\nnum_epochs = 30  \n\ndef load_data(dataset_path):\n    instance_to_images = defaultdict(list)\n    labels = dict()\n\n    for category in os.listdir(dataset_path):\n        category_path = os.path.join(dataset_path, category)\n        if not os.path.isdir(category_path):\n            continue\n\n        for instance in os.listdir(category_path):\n            instance_path = os.path.join(category_path, instance)\n            if not os.path.isdir(instance_path):\n                continue\n\n            for img_name in os.listdir(instance_path):\n                if img_name.endswith(\".png\") or img_name.endswith(\".jpg\"):\n                    full_path = os.path.join(instance_path, img_name)\n                    instance_to_images[instance].append(full_path)\n                    labels[instance] = category\n\n    return instance_to_images, labels\n\ndef split_instances(instances, labels, test_size=0.25, val_size=0.25):\n    all_instances = list(instances.keys())\n    all_labels = [labels[i] for i in all_instances]\n\n    train_val_instances, test_instances = train_test_split(\n        all_instances, test_size=test_size, stratify=all_labels, random_state=42)\n\n    train_val_labels = [labels[i] for i in train_val_instances]\n\n    train_instances, val_instances = train_test_split(\n        train_val_instances, test_size=val_size, stratify=train_val_labels, random_state=42)\n\n    return train_instances, val_instances, test_instances\n\nclass RGBDDataset(Dataset):\n    def __init__(self, instances, instance_to_images, labels, transform=None):\n        self.image_paths = []\n        self.image_labels = []\n        for inst in instances:\n            for path in instance_to_images[inst]:\n                self.image_paths.append(path)\n                self.image_labels.append(labels[inst])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert('RGB')\n        label = self.image_labels[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\ndef prepare_dataloaders(instance_to_images, labels, splits):\n    train_instances, val_instances, test_instances = splits\n    le = LabelEncoder()\n    le.fit([labels[i] for i in instance_to_images])\n\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    train_dataset = RGBDDataset(train_instances, instance_to_images, labels, transform)\n    val_dataset = RGBDDataset(val_instances, instance_to_images, labels, transform)\n    test_dataset = RGBDDataset(test_instances, instance_to_images, labels, transform)\n\n    train_dataset.image_labels = le.transform(train_dataset.image_labels)\n    val_dataset.image_labels = le.transform(val_dataset.image_labels)\n    test_dataset.image_labels = le.transform(test_dataset.image_labels)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, val_loader, test_loader, le\n\ndef train_and_evaluate_resnet(train_loader, val_loader, test_loader, le, num_classes):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = models.resnet18(pretrained=True)\n    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n    model.to(device)\n\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n    train_losses, train_accuracies = [], []\n    val_losses, val_accuracies = [], []\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        correct_train = 0\n        total_train = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n            _, preds = torch.max(outputs, 1)\n            correct_train += (preds == labels).sum().item()\n            total_train += labels.size(0)\n\n        train_loss = total_loss\n        train_acc = 100 * correct_train / total_train\n        train_losses.append(train_loss)\n        train_accuracies.append(train_acc)\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        correct_val = 0\n        total_val = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                correct_val += (preds == labels).sum().item()\n                total_val += labels.size(0)\n\n        val_losses.append(val_loss)\n        val_accuracies.append(100 * correct_val / total_val)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracies[-1]:.2f}%\")\n\n    # Test performance\n    all_preds = []\n    all_labels = []\n    model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.numpy())\n\n    print(\"\\nTest Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n    print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n\n    # Confusion Matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n    # Plotting Loss and Accuracy\n    epochs = list(range(1, num_epochs + 1))\n    plt.figure(figsize=(12, 6))\n\n    # Loss Plot\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n    plt.plot(epochs, val_losses, label='Val Loss', marker='o')\n    plt.title('Loss per Epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Accuracy Plot\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, label='Train Accuracy', marker='o')\n    plt.plot(epochs, val_accuracies, label='Val Accuracy', marker='o')\n    plt.title('Accuracy per Epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Pipeline Execution\ninstance_to_images, labels = load_data(dataset_path)\nsplits = split_instances(instance_to_images, labels, test_size=0.25, val_size=0.25)\ntrain_loader, val_loader, test_loader, le = prepare_dataloaders(instance_to_images, labels, splits)\ntrain_and_evaluate_resnet(train_loader, val_loader, test_loader, le, num_classes=len(le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:41:19.557482Z","iopub.execute_input":"2025-05-13T17:41:19.557860Z","iopub.status.idle":"2025-05-13T20:17:22.836311Z","shell.execute_reply.started":"2025-05-13T17:41:19.557813Z","shell.execute_reply":"2025-05-13T20:17:22.835556Z"}},"outputs":[],"execution_count":null}]}