{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11690806,"sourceType":"datasetVersion","datasetId":7337770}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.model_selection import train_test_split\n\n# ------------------ Load Data ------------------\n\ndef load_rgbd_data(data_path):\n    instance_to_images = {}\n    labels = {}\n\n    for category in os.listdir(data_path):\n        category_path = os.path.join(data_path, category)\n        if not os.path.isdir(category_path):\n            continue\n\n        for instance in os.listdir(category_path):\n            instance_path = os.path.join(category_path, instance)\n            if not os.path.isdir(instance_path):\n                continue\n\n            image_paths = [\n                os.path.join(instance_path, f)\n                for f in os.listdir(instance_path)\n                if f.endswith(\".png\") or f.endswith(\".jpg\")\n            ]\n            instance_to_images[instance] = image_paths\n            labels[instance] = category\n\n    return instance_to_images, labels\n\n# ------------------ Feature Extraction ------------------\n\ndef extract_sift_descriptors(image_paths):\n    sift = cv2.SIFT_create()\n    descriptors_list = []\n    for path in image_paths:\n        img = cv2.imread(path)\n        if img is None:\n            continue\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        keypoints, descriptors = sift.detectAndCompute(gray, None)\n        if descriptors is not None:\n            descriptors_list.append(descriptors)\n    return descriptors_list\n\n# ------------------ BoVW Codebook ------------------\n\ndef build_codebook(descriptor_list, k):\n    all_descriptors = np.vstack(descriptor_list)\n    kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n    kmeans.fit(all_descriptors)\n    return kmeans\n\n# ------------------ BoVW Histogram ------------------\n\ndef compute_bovw_histogram(descriptors_list, kmeans):\n    histograms = []\n    for descriptors in descriptors_list:\n        if descriptors is None:\n            hist = np.zeros(kmeans.n_clusters)\n        else:\n            words = kmeans.predict(descriptors)\n            hist, _ = np.histogram(words, bins=np.arange(kmeans.n_clusters + 1))\n        histograms.append(hist)\n    return np.array(histograms)\n\n# ------------------ Dataset Preparation ------------------\n\ndef prepare_dataset(instance_to_images, labels, train_instances, val_instances, test_instances, k):\n    le = LabelEncoder()\n    y_train = le.fit_transform([labels[i] for i in train_instances])\n    y_val = le.transform([labels[i] for i in val_instances]) if val_instances else []\n    y_test = le.transform([labels[i] for i in test_instances]) if test_instances else []\n\n    train_descriptors = []\n    for inst in train_instances:\n        descs = extract_sift_descriptors(instance_to_images[inst])\n        train_descriptors.extend(descs)\n\n    kmeans = build_codebook(train_descriptors, k)\n\n    X_train = compute_bovw_histogram(\n        [desc for inst in train_instances for desc in extract_sift_descriptors(instance_to_images[inst])],\n        kmeans\n    )\n    X_val = compute_bovw_histogram(\n        [desc for inst in val_instances for desc in extract_sift_descriptors(instance_to_images[inst])],\n        kmeans\n    ) if val_instances else []\n    X_test = compute_bovw_histogram(\n        [desc for inst in test_instances for desc in extract_sift_descriptors(instance_to_images[inst])],\n        kmeans\n    ) if test_instances else []\n\n    return X_train, y_train, X_val, y_val, X_test, y_test, le, kmeans\n\n# ------------------ Grid Search ------------------\n\ndef grid_search_svm(instance_to_images, labels, train_instances, val_instances, le,\n                    k_values=[50, 100, 150],\n                    C_values=[0.01, 0.1, 1, 10]):\n    best_score = 0\n    best_k = None\n    best_C = None\n\n    for k in k_values:\n        print(f\"\\nTesting BoVW size k = {k}\")\n        try:\n            X_train, y_train, X_val, y_val, _, _, _, _ = prepare_dataset(\n                instance_to_images, labels, train_instances, val_instances, [], k\n            )\n        except Exception as e:\n            print(f\"  Skipping k={k} due to error: {e}\")\n            continue\n\n        for C in C_values:\n            model = SVC(kernel='linear', C=C)\n            model.fit(X_train, y_train)\n            score = accuracy_score(y_val, model.predict(X_val))\n            print(f\"    C = {C:.3f} → Accuracy: {score:.4f}\")\n\n            if score > best_score:\n                best_score = score\n                best_k = k\n                best_C = C\n\n    print(f\"\\nBest Grid Search → k = {best_k}, C = {best_C}, Accuracy = {best_score:.4f}\")\n    return best_k, best_C\n\n# ------------------ Confusion Matrix Plot ------------------\n\ndef plot_confusion_matrix(y_true, y_pred, label_encoder):\n    cm = confusion_matrix(y_true, y_pred)\n    labels = label_encoder.classes_\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=labels, yticklabels=labels)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix\")\n    plt.xticks(rotation=90)\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n    plt.show()\n\n# ------------------ Main Execution ------------------\n\n# Load and split data\ndata_path = '/kaggle/input/rgb-d-cropped/rgbd-dataset_eval'  \ninstance_to_images, labels = load_rgbd_data(data_path)\n\ninstances = list(instance_to_images.keys())\nrandom.seed(42)\nrandom.shuffle(instances)\n\ntrain_size = int(0.6 * len(instances))\nval_size = int(0.2 * len(instances))\n\ntrain_instances = instances[:train_size]\nval_instances = instances[train_size:train_size + val_size]\ntest_instances = instances[train_size + val_size:]\n\n# Grid Search\nlabel_encoder = LabelEncoder()\nbest_k, best_C = grid_search_svm(instance_to_images, labels, train_instances, val_instances, label_encoder)\n\n# Final training on train+val and testing\nX_train, y_train, _, _, X_test, y_test, le, _ = prepare_dataset(\n    instance_to_images, labels, train_instances + val_instances, [], test_instances, best_k\n)\n\nfinal_model = SVC(kernel='linear', C=best_C)\nfinal_model.fit(X_train, y_train)\ny_pred = final_model.predict(X_test)\n\n# Accuracy and Confusion Matrix\nfinal_acc = accuracy_score(y_test, y_pred)\nprint(f\"\\n✅ Final Test Accuracy: {final_acc:.4f}\")\nplot_confusion_matrix(y_test, y_pred, le)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-09T00:59:30.068Z"}},"outputs":[],"execution_count":null}]}